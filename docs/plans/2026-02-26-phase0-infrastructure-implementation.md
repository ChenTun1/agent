# Phase 0: åŸºç¡€è®¾æ–½å‡†å¤‡ - å®æ–½è®¡åˆ’

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**ç›®æ ‡**: æ­å»ºä¼ä¸šçº§åŸºç¡€è®¾æ–½,ä¸ºåç»­å¼€å‘å¥ å®šåŸºç¡€

**æ¶æ„**: Docker Compose ç¼–æ’ Redis + Qdrant,åˆ›å»º SQLite æ•°æ®åº“,é…ç½® Celery ä»»åŠ¡é˜Ÿåˆ—

**æŠ€æœ¯æ ˆ**: Docker, Redis 7.0, Celery 5.3, SQLite 3.40, pytest

**é¢„è®¡æ—¶é—´**: 2-3 å¤©

---

## å‰ç½®æ£€æŸ¥

**éªŒè¯ç°æœ‰ç¯å¢ƒ**:
```bash
python --version  # åº”ä¸º 3.11+
docker --version  # åº”ä¸º 24.0+
docker-compose --version
```

---

## Task 1: Docker Compose é…ç½®

**æ–‡ä»¶**:
- Create: `docker-compose.yml`
- Create: `.env.example`

**Step 1: åˆ›å»º Docker Compose é…ç½®**

```yaml
# docker-compose.yml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    container_name: ai-pdf-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: ai-pdf-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 10s
      timeout: 3s
      retries: 3

volumes:
  redis_data:
    driver: local
  qdrant_data:
    driver: local
```

**Step 2: åˆ›å»ºç¯å¢ƒå˜é‡æ¨¡æ¿**

```bash
# .env.example
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å†™å®é™…å€¼

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Celery
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# Database
DATABASE_URL=sqlite:///data/app.db

# API Keys
ANTHROPIC_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
```

**Step 3: å¯åŠ¨æœåŠ¡**

```bash
# åˆ›å»º .env æ–‡ä»¶
cp .env.example .env

# å¯åŠ¨ Docker æœåŠ¡
docker-compose up -d

# ç­‰å¾…æœåŠ¡å°±ç»ª
sleep 10
```

**Step 4: éªŒè¯æœåŠ¡è¿è¡Œ**

```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker-compose ps

# é¢„æœŸè¾“å‡º:
#     Name                   State    Ports
# ai-pdf-redis      Up      0.0.0.0:6379->6379/tcp
# ai-pdf-qdrant     Up      0.0.0.0:6333->6333/tcp

# æµ‹è¯• Redis è¿æ¥
docker exec ai-pdf-redis redis-cli ping
# é¢„æœŸ: PONG

# æµ‹è¯• Qdrant å¥åº·æ£€æŸ¥
curl http://localhost:6333/health
# é¢„æœŸ: {"status":"ok"}
```

**Step 5: æäº¤**

```bash
git add docker-compose.yml .env.example
git commit -m "chore: add Docker Compose for Redis and Qdrant

- Redis 7 with persistence and LRU eviction
- Qdrant 1.7.4 for vector storage
- Health checks for both services
- Volume configuration for data persistence

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 2: Python ä¾èµ–æ›´æ–°

**æ–‡ä»¶**:
- Modify: `requirements.txt`
- Create: `requirements-dev.txt`

**Step 1: æ›´æ–° requirements.txt**

æ·»åŠ æ–°ä¾èµ–åˆ°ç°æœ‰æ–‡ä»¶:

```txt
# requirements.txt (åœ¨ç°æœ‰å†…å®¹åŸºç¡€ä¸Šæ·»åŠ )

# ç°æœ‰ä¾èµ– (ä¿æŒä¸å˜)
fastapi==0.110.0
uvicorn[standard]==0.40.0
python-multipart==0.0.6
pydantic==2.11.7
pydantic-settings==2.1.0
pypdf==3.17.4
anthropic==0.75.0
openai==2.18.0
qdrant-client==1.17.0
psycopg2-binary==2.9.9
sqlalchemy==2.0.25
streamlit==1.31.0
python-dotenv==1.0.0
httpx==0.26.0

# æ–°å¢ä¾èµ–
rank-bm25==0.2.2           # BM25 ç¨€ç–æ£€ç´¢
celery==5.3.6              # ä»»åŠ¡é˜Ÿåˆ—
redis==5.0.1               # Redis å®¢æˆ·ç«¯
jieba==0.42.1              # ä¸­æ–‡åˆ†è¯
slowapi==0.1.9             # API é™æµ
structlog==24.1.0          # ç»“æ„åŒ–æ—¥å¿—
```

**Step 2: åˆ›å»ºå¼€å‘ä¾èµ–**

```txt
# requirements-dev.txt
-r requirements.txt

# æµ‹è¯•
pytest==9.0.2
pytest-asyncio==1.3.0
pytest-cov==6.0.0
pytest-mock==3.12.0

# ä»£ç è´¨é‡
black==24.2.0
isort==5.13.2
flake8==7.0.0
mypy==1.8.0

# æ€§èƒ½åˆ†æ
py-spy==0.3.14
memory-profiler==0.61.0
```

**Step 3: å®‰è£…ä¾èµ–**

```bash
# å®‰è£…ç”Ÿäº§ä¾èµ–
pip install -r requirements.txt

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt
```

**Step 4: éªŒè¯å®‰è£…**

```bash
# éªŒè¯å…³é”®åŒ…
python -c "import redis; print(f'Redis: {redis.__version__}')"
python -c "import celery; print(f'Celery: {celery.__version__}')"
python -c "import rank_bm25; print('BM25: OK')"
python -c "import jieba; print('Jieba: OK')"

# é¢„æœŸ: æ‰€æœ‰åŒ…æˆåŠŸå¯¼å…¥
```

**Step 5: æäº¤**

```bash
git add requirements.txt requirements-dev.txt
git commit -m "chore: add enterprise-level dependencies

New dependencies:
- rank-bm25: Sparse retrieval (BM25)
- celery: Async task queue
- redis: Cache layer
- jieba: Chinese word segmentation
- slowapi: Rate limiting
- structlog: Structured logging

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 3: SQLite æ•°æ®åº“è®¾ç½®

**æ–‡ä»¶**:
- Create: `backend/database.py`
- Create: `backend/models_db.py`
- Create: `data/.gitkeep`

**Step 1: åˆ›å»ºæ•°æ®ç›®å½•**

```bash
mkdir -p data
touch data/.gitkeep
```

**Step 2: ç¼–å†™æ•°æ®åº“æ¨¡å‹**

```python
# backend/models_db.py
"""
SQLAlchemy æ•°æ®åº“æ¨¡å‹

ç”¨äºå­˜å‚¨æ–‡æ¡£å…ƒæ•°æ®ã€å¯¹è¯å†å²ç­‰
"""
from sqlalchemy import Column, String, Integer, Text, DateTime, ForeignKey, Index
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()


class Document(Base):
    """æ–‡æ¡£è¡¨ - å­˜å‚¨ PDF å…ƒæ•°æ®"""
    __tablename__ = 'documents'

    id = Column(String(36), primary_key=True)
    filename = Column(String(255), nullable=False)
    page_count = Column(Integer, nullable=False)
    file_size = Column(Integer, nullable=False)
    upload_time = Column(DateTime, default=datetime.utcnow, nullable=False)
    metadata = Column(Text)  # JSON æ ¼å¼å­˜å‚¨é¢å¤–ä¿¡æ¯

    # å…³ç³»
    conversations = relationship(
        'Conversation',
        back_populates='document',
        cascade='all, delete-orphan'
    )

    def __repr__(self):
        return f"<Document(id={self.id}, filename={self.filename})>"


class Conversation(Base):
    """å¯¹è¯è¡¨ - å­˜å‚¨å¯¹è¯ä¼šè¯"""
    __tablename__ = 'conversations'

    id = Column(String(36), primary_key=True)
    document_id = Column(
        String(36),
        ForeignKey('documents.id', ondelete='CASCADE'),
        nullable=False
    )
    title = Column(String(255))  # å¯¹è¯æ ‡é¢˜ (é€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªé—®é¢˜)
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(
        DateTime,
        default=datetime.utcnow,
        onupdate=datetime.utcnow,
        nullable=False
    )

    # å…³ç³»
    document = relationship('Document', back_populates='conversations')
    messages = relationship(
        'Message',
        back_populates='conversation',
        cascade='all, delete-orphan',
        order_by='Message.created_at'
    )

    # ç´¢å¼•
    __table_args__ = (
        Index('idx_conversation_document', 'document_id'),
        Index('idx_conversation_updated', 'updated_at'),
    )

    def __repr__(self):
        return f"<Conversation(id={self.id}, title={self.title})>"


class Message(Base):
    """æ¶ˆæ¯è¡¨ - å­˜å‚¨å¯¹è¯æ¶ˆæ¯"""
    __tablename__ = 'messages'

    id = Column(String(36), primary_key=True)
    conversation_id = Column(
        String(36),
        ForeignKey('conversations.id', ondelete='CASCADE'),
        nullable=False
    )
    role = Column(String(20), nullable=False)  # 'user' or 'assistant'
    content = Column(Text, nullable=False)
    sources = Column(Text)  # JSON æ ¼å¼å­˜å‚¨æ¥æº
    cited_pages = Column(Text)  # JSON æ ¼å¼å­˜å‚¨å¼•ç”¨é¡µç 
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)

    # å…³ç³»
    conversation = relationship('Conversation', back_populates='messages')

    # ç´¢å¼•
    __table_args__ = (
        Index('idx_message_conversation', 'conversation_id'),
        Index('idx_message_created', 'created_at'),
    )

    def __repr__(self):
        return f"<Message(id={self.id}, role={self.role})>"
```

**Step 3: ç¼–å†™æ•°æ®åº“ç®¡ç†å™¨**

```python
# backend/database.py
"""
æ•°æ®åº“è¿æ¥å’Œä¼šè¯ç®¡ç†
"""
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import StaticPool
from contextlib import contextmanager
import os

from backend.models_db import Base

# æ•°æ®åº“ URL
DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///data/app.db')


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼"""

    _instance = None
    _engine = None
    _SessionLocal = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if self._engine is None:
            self._init_engine()

    def _init_engine(self):
        """åˆå§‹åŒ–æ•°æ®åº“å¼•æ“"""
        # SQLite ç‰¹æ®Šé…ç½®
        if DATABASE_URL.startswith('sqlite'):
            self._engine = create_engine(
                DATABASE_URL,
                connect_args={'check_same_thread': False},
                poolclass=StaticPool,
                echo=False
            )
        else:
            self._engine = create_engine(DATABASE_URL, echo=False)

        self._SessionLocal = sessionmaker(
            autocommit=False,
            autoflush=False,
            bind=self._engine
        )

    def create_tables(self):
        """åˆ›å»ºæ‰€æœ‰è¡¨"""
        Base.metadata.create_all(bind=self._engine)
        print("[DB] Tables created successfully")

    def drop_tables(self):
        """åˆ é™¤æ‰€æœ‰è¡¨ (æ…ç”¨!)"""
        Base.metadata.drop_all(bind=self._engine)
        print("[DB] Tables dropped")

    def get_session(self) -> Session:
        """è·å–æ•°æ®åº“ä¼šè¯"""
        return self._SessionLocal()

    @contextmanager
    def session_scope(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - è‡ªåŠ¨æäº¤å’Œå›æ»š"""
        session = self.get_session()
        try:
            yield session
            session.commit()
        except Exception:
            session.rollback()
            raise
        finally:
            session.close()


# å…¨å±€å®ä¾‹
db_manager = DatabaseManager()


# FastAPI ä¾èµ–æ³¨å…¥
def get_db():
    """è·å–æ•°æ®åº“ä¼šè¯ (ç”¨äº FastAPI Depends)"""
    db = db_manager.get_session()
    try:
        yield db
    finally:
        db.close()
```

**Step 4: åˆå§‹åŒ–æ•°æ®åº“**

```python
# scripts/init_db.py
"""åˆå§‹åŒ–æ•°æ®åº“è„šæœ¬"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from backend.database import db_manager


def main():
    print("Initializing database...")

    # åˆ›å»ºè¡¨
    db_manager.create_tables()

    print("âœ“ Database initialized successfully!")
    print(f"  Location: data/app.db")
    print(f"  Tables: documents, conversations, messages")


if __name__ == '__main__':
    main()
```

**Step 5: è¿è¡Œåˆå§‹åŒ–**

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data

# è¿è¡Œåˆå§‹åŒ–è„šæœ¬
python scripts/init_db.py

# é¢„æœŸè¾“å‡º:
# Initializing database...
# [DB] Tables created successfully
# âœ“ Database initialized successfully!
```

**Step 6: éªŒè¯æ•°æ®åº“**

```bash
# ä½¿ç”¨ sqlite3 æ£€æŸ¥è¡¨ç»“æ„
sqlite3 data/app.db ".schema documents"

# é¢„æœŸè¾“å‡º:
# CREATE TABLE documents (
#   id VARCHAR(36) NOT NULL,
#   filename VARCHAR(255) NOT NULL,
#   ...
# );
```

**Step 7: æäº¤**

```bash
git add backend/database.py backend/models_db.py scripts/init_db.py data/.gitkeep
git commit -m "feat: add SQLite database with SQLAlchemy models

Tables:
- documents: PDF metadata
- conversations: Chat sessions
- messages: Chat messages

Features:
- Foreign key constraints with CASCADE delete
- Indexes for performance
- Session management with context manager
- Initialization script

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 4: Celery é…ç½®

**æ–‡ä»¶**:
- Create: `backend/celeryconfig.py`
- Create: `backend/celery_app.py`
- Create: `scripts/start_celery.sh`

**Step 1: Celery é…ç½®æ–‡ä»¶**

```python
# backend/celeryconfig.py
"""Celery é…ç½®"""
import os

# Broker é…ç½®
broker_url = os.getenv('CELERY_BROKER_URL', 'redis://localhost:6379/0')
result_backend = os.getenv('CELERY_RESULT_BACKEND', 'redis://localhost:6379/1')

# ä»»åŠ¡é…ç½®
task_serializer = 'json'
result_serializer = 'json'
accept_content = ['json']
timezone = 'Asia/Shanghai'
enable_utc = True

# ä»»åŠ¡ç»“æœè¿‡æœŸæ—¶é—´ (1å°æ—¶)
result_expires = 3600

# Worker é…ç½®
worker_prefetch_multiplier = 4
worker_max_tasks_per_child = 1000

# ä»»åŠ¡è·¯ç”±
task_routes = {
    'backend.tasks.pdf.*': {'queue': 'pdf_processing'},
    'backend.tasks.embedding.*': {'queue': 'embedding'},
}

# é˜Ÿåˆ—é…ç½®
task_queues = {
    'pdf_processing': {
        'exchange': 'pdf',
        'routing_key': 'pdf.processing',
    },
    'embedding': {
        'exchange': 'embedding',
        'routing_key': 'embedding.compute',
    },
    'default': {
        'exchange': 'default',
        'routing_key': 'default',
    }
}
```

**Step 2: Celery åº”ç”¨**

```python
# backend/celery_app.py
"""Celery åº”ç”¨å®ä¾‹"""
from celery import Celery

# åˆ›å»º Celery åº”ç”¨
celery_app = Celery('ai_pdf_chat')

# åŠ è½½é…ç½®
celery_app.config_from_object('backend.celeryconfig')

# è‡ªåŠ¨å‘ç°ä»»åŠ¡
celery_app.autodiscover_tasks(['backend.tasks'])


@celery_app.task(bind=True)
def debug_task(self):
    """è°ƒè¯•ä»»åŠ¡"""
    print(f'Request: {self.request!r}')
    return 'Debug task completed'
```

**Step 3: å¯åŠ¨è„šæœ¬**

```bash
# scripts/start_celery.sh
#!/bin/bash

# Celery Worker å¯åŠ¨è„šæœ¬

echo "Starting Celery worker..."

# å¯åŠ¨ Worker
celery -A backend.celery_app worker \
    --loglevel=info \
    --concurrency=4 \
    --queues=pdf_processing,embedding,default \
    --logfile=logs/celery.log

# æ³¨: ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ supervisord æˆ– systemd ç®¡ç†
```

**Step 4: ä½¿å¯åŠ¨è„šæœ¬å¯æ‰§è¡Œ**

```bash
chmod +x scripts/start_celery.sh
```

**Step 5: æµ‹è¯• Celery**

åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶:

```python
# test_celery.py (ä¸´æ—¶)
from backend.celery_app import celery_app, debug_task

# æäº¤ä»»åŠ¡
result = debug_task.delay()

print(f"Task ID: {result.id}")
print(f"Task State: {result.state}")

# ç­‰å¾…ç»“æœ (æœ€å¤š 10 ç§’)
try:
    output = result.get(timeout=10)
    print(f"Result: {output}")
except Exception as e:
    print(f"Error: {e}")
```

è¿è¡Œæµ‹è¯•:

```bash
# ç»ˆç«¯ 1: å¯åŠ¨ Worker
./scripts/start_celery.sh

# ç»ˆç«¯ 2: è¿è¡Œæµ‹è¯•
python test_celery.py

# é¢„æœŸè¾“å‡º:
# Task ID: xxxxx-xxxx-xxxx
# Task State: SUCCESS
# Result: Debug task completed

# æ¸…ç†æµ‹è¯•æ–‡ä»¶
rm test_celery.py
```

**Step 6: æäº¤**

```bash
git add backend/celeryconfig.py backend/celery_app.py scripts/start_celery.sh
git commit -m "feat: add Celery task queue configuration

Features:
- Redis as broker and result backend
- Multiple queues (pdf_processing, embedding)
- Worker concurrency configuration
- Task routing
- Startup script

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 5: å¥åº·æ£€æŸ¥è„šæœ¬

**æ–‡ä»¶**:
- Create: `scripts/check_infrastructure.sh`
- Create: `backend/health.py`

**Step 1: å¥åº·æ£€æŸ¥è„šæœ¬**

```bash
# scripts/check_infrastructure.sh
#!/bin/bash

# åŸºç¡€è®¾æ–½å¥åº·æ£€æŸ¥è„šæœ¬

echo "=== Infrastructure Health Check ==="
echo ""

# é¢œè‰²è¾“å‡º
GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m' # No Color

check_passed=0
check_failed=0

# æ£€æŸ¥å‡½æ•°
check() {
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}âœ“${NC} $1"
        ((check_passed++))
    else
        echo -e "${RED}âœ—${NC} $1"
        ((check_failed++))
    fi
}

# 1. æ£€æŸ¥ Docker
echo "1. Docker Services"
docker ps | grep -q ai-pdf-redis
check "Redis container running"

docker ps | grep -q ai-pdf-qdrant
check "Qdrant container running"

# 2. æ£€æŸ¥ Redis è¿æ¥
echo ""
echo "2. Redis Connection"
docker exec ai-pdf-redis redis-cli ping > /dev/null 2>&1
check "Redis ping successful"

# 3. æ£€æŸ¥ Qdrant å¥åº·
echo ""
echo "3. Qdrant Connection"
curl -s http://localhost:6333/health | grep -q "ok"
check "Qdrant health check passed"

# 4. æ£€æŸ¥ SQLite æ•°æ®åº“
echo ""
echo "4. SQLite Database"
[ -f data/app.db ]
check "Database file exists"

sqlite3 data/app.db "SELECT name FROM sqlite_master WHERE type='table';" | grep -q documents
check "Documents table exists"

# 5. æ£€æŸ¥ Python ä¾èµ–
echo ""
echo "5. Python Dependencies"
python -c "import redis" 2>/dev/null
check "Redis Python client installed"

python -c "import celery" 2>/dev/null
check "Celery installed"

python -c "import rank_bm25" 2>/dev/null
check "BM25 installed"

python -c "import jieba" 2>/dev/null
check "Jieba installed"

# 6. æ£€æŸ¥ Celery Worker
echo ""
echo "6. Celery Worker"
celery -A backend.celery_app inspect ping > /dev/null 2>&1
if [ $? -eq 0 ]; then
    check "Celery worker responding"
else
    echo -e "${RED}âœ—${NC} Celery worker not running (optional for now)"
fi

# æ€»ç»“
echo ""
echo "==================================="
echo "Passed: $check_passed"
echo "Failed: $check_failed"

if [ $check_failed -eq 0 ]; then
    echo -e "${GREEN}All checks passed!${NC}"
    exit 0
else
    echo -e "${RED}Some checks failed.${NC}"
    exit 1
fi
```

**Step 2: Python å¥åº·æ£€æŸ¥æ¨¡å—**

```python
# backend/health.py
"""å¥åº·æ£€æŸ¥å·¥å…·"""
import redis
from qdrant_client import QdrantClient
from sqlalchemy import text
import os

from backend.database import db_manager


class HealthChecker:
    """åŸºç¡€è®¾æ–½å¥åº·æ£€æŸ¥å™¨"""

    def check_redis(self) -> dict:
        """æ£€æŸ¥ Redis è¿æ¥"""
        try:
            r = redis.Redis(
                host=os.getenv('REDIS_HOST', 'localhost'),
                port=int(os.getenv('REDIS_PORT', 6379)),
                db=int(os.getenv('REDIS_DB', 0))
            )
            r.ping()
            info = r.info()

            return {
                'status': 'healthy',
                'version': info.get('redis_version'),
                'memory': info.get('used_memory_human'),
                'connected_clients': info.get('connected_clients')
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }

    def check_qdrant(self) -> dict:
        """æ£€æŸ¥ Qdrant è¿æ¥"""
        try:
            client = QdrantClient(
                host=os.getenv('QDRANT_HOST', 'localhost'),
                port=int(os.getenv('QDRANT_PORT', 6333))
            )
            collections = client.get_collections()

            return {
                'status': 'healthy',
                'collections': len(collections.collections)
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }

    def check_database(self) -> dict:
        """æ£€æŸ¥ SQLite æ•°æ®åº“"""
        try:
            with db_manager.session_scope() as session:
                # æµ‹è¯•æŸ¥è¯¢
                result = session.execute(text("SELECT 1"))
                result.scalar()

                # æ£€æŸ¥è¡¨
                tables = session.execute(text(
                    "SELECT name FROM sqlite_master WHERE type='table'"
                )).fetchall()

                return {
                    'status': 'healthy',
                    'tables': [t[0] for t in tables]
                }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }

    def check_all(self) -> dict:
        """æ‰§è¡Œæ‰€æœ‰å¥åº·æ£€æŸ¥"""
        return {
            'redis': self.check_redis(),
            'qdrant': self.check_qdrant(),
            'database': self.check_database()
        }


# å¿«æ·å‡½æ•°
def health_check() -> dict:
    """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
    checker = HealthChecker()
    return checker.check_all()
```

**Step 3: ä½¿è„šæœ¬å¯æ‰§è¡Œ**

```bash
chmod +x scripts/check_infrastructure.sh
```

**Step 4: è¿è¡Œå¥åº·æ£€æŸ¥**

```bash
./scripts/check_infrastructure.sh

# é¢„æœŸè¾“å‡º:
# === Infrastructure Health Check ===
# 1. Docker Services
# âœ“ Redis container running
# âœ“ Qdrant container running
# ...
# Passed: 8
# Failed: 0
# All checks passed!
```

**Step 5: æäº¤**

```bash
git add scripts/check_infrastructure.sh backend/health.py
git commit -m "feat: add infrastructure health check tools

Features:
- Bash script for automated checks
- Python module for programmatic health checks
- Checks Redis, Qdrant, SQLite, and dependencies
- Color-coded output

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## Task 6: æ–‡æ¡£å’ŒéªŒæ”¶

**æ–‡ä»¶**:
- Create: `docs/phase0-completion.md`
- Modify: `README.md`

**Step 1: åˆ›å»ºé˜¶æ®µå®Œæˆæ–‡æ¡£**

```markdown
# Phase 0: åŸºç¡€è®¾æ–½å‡†å¤‡ - å®ŒæˆæŠ¥å‘Š

**å®Œæˆæ—¥æœŸ**: 2026-02-26
**çŠ¶æ€**: âœ… å·²å®Œæˆ

## å·²å®Œæˆé¡¹ç›®

### 1. Docker æœåŠ¡
- âœ… Redis 7-alpine (ç¼“å­˜å±‚)
- âœ… Qdrant 1.7.4 (å‘é‡æ•°æ®åº“)
- âœ… Docker Compose ç¼–æ’
- âœ… å¥åº·æ£€æŸ¥é…ç½®

### 2. Python ä¾èµ–
- âœ… rank-bm25 (BM25 æ£€ç´¢)
- âœ… celery (ä»»åŠ¡é˜Ÿåˆ—)
- âœ… redis (Redis å®¢æˆ·ç«¯)
- âœ… jieba (ä¸­æ–‡åˆ†è¯)
- âœ… å…¶ä»–ä¼ä¸šçº§ä¾èµ–

### 3. SQLite æ•°æ®åº“
- âœ… æ•°æ®åº“æ¨¡å‹ (Document, Conversation, Message)
- âœ… SQLAlchemy ORM é…ç½®
- âœ… ä¼šè¯ç®¡ç†
- âœ… åˆå§‹åŒ–è„šæœ¬

### 4. Celery ä»»åŠ¡é˜Ÿåˆ—
- âœ… Celery åº”ç”¨é…ç½®
- âœ… å¤šé˜Ÿåˆ—æ”¯æŒ
- âœ… Worker å¯åŠ¨è„šæœ¬

### 5. å¥åº·æ£€æŸ¥
- âœ… Bash è‡ªåŠ¨åŒ–æ£€æŸ¥è„šæœ¬
- âœ… Python å¥åº·æ£€æŸ¥æ¨¡å—

## éªŒæ”¶ç»“æœ

```bash
./scripts/check_infrastructure.sh
```

**ç»“æœ**: æ‰€æœ‰æ£€æŸ¥é€šè¿‡ âœ…

## ä¸‹ä¸€æ­¥

Phase 1: æ ¸å¿ƒç®—æ³•å®ç° (æ··åˆæ£€ç´¢ã€æ™ºèƒ½åˆ†å—)

å‚è§: `docs/plans/2026-02-26-phase1-hybrid-retrieval-implementation.md`
```

**Step 2: æ›´æ–° README**

åœ¨ README.md ä¸­æ·»åŠ åŸºç¡€è®¾æ–½éƒ¨åˆ†:

```markdown
## ğŸ› ï¸ åŸºç¡€è®¾æ–½

### å¯åŠ¨æœåŠ¡

```bash
# 1. å¯åŠ¨ Docker æœåŠ¡
docker-compose up -d

# 2. åˆå§‹åŒ–æ•°æ®åº“
python scripts/init_db.py

# 3. éªŒè¯ç¯å¢ƒ
./scripts/check_infrastructure.sh
```

### æœåŠ¡ç«¯å£

- **Redis**: http://localhost:6379
- **Qdrant**: http://localhost:6333
- **Qdrant UI**: http://localhost:6334/dashboard

### åœæ­¢æœåŠ¡

```bash
docker-compose down
```
```

**Step 3: æäº¤**

```bash
git add docs/phase0-completion.md README.md
git commit -m "docs: complete Phase 0 infrastructure setup

All infrastructure components verified and operational:
- Docker services (Redis + Qdrant)
- Python dependencies
- SQLite database
- Celery task queue
- Health check tools

Ready for Phase 1: Core Algorithm Implementation

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

---

## éªŒæ”¶æ ‡å‡†

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯ Phase 0 å®Œæˆ:

```bash
# 1. å¥åº·æ£€æŸ¥
./scripts/check_infrastructure.sh

# é¢„æœŸ: All checks passed!

# 2. æœåŠ¡çŠ¶æ€
docker-compose ps

# é¢„æœŸ: æ‰€æœ‰æœåŠ¡ State=Up

# 3. Python å¯¼å…¥æµ‹è¯•
python -c "
import redis
import celery
import rank_bm25
import jieba
from backend.database import db_manager
from backend.health import health_check
print('All imports successful!')
"

# é¢„æœŸ: All imports successful!

# 4. æ•°æ®åº“è¡¨æ£€æŸ¥
sqlite3 data/app.db ".tables"

# é¢„æœŸ: conversations  documents  messages
```

---

## ä¸‹ä¸€æ­¥

Phase 0 å®Œæˆå,ç»§ç»­ **Phase 1: æ ¸å¿ƒç®—æ³•å®ç°**

å‚è§: `docs/plans/2026-02-26-phase1-hybrid-retrieval-implementation.md`
